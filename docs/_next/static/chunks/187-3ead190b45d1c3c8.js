(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[187],{2393:function(e,i,n){"use strict";function s(e){return{...e}}n.d(i,{a:function(){return s}})},2187:function(e,i,n){"use strict";n.r(i),n.d(i,{default:function(){return h}});var s=n(5893),t=n(2393),a=n(9008),r=n.n(a),d=n(1528),l=n.n(d);function c(e){let i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r(),{children:(0,s.jsx)("title",{children:'Introducing "Bhasha" Indic Language AI Datasets'})}),"\n",(0,s.jsxs)("div",{className:l().Blogs,children:[(0,s.jsx)(i.p,{children:(0,s.jsx)(i.code,{children:"17th April, 2024"})}),(0,s.jsx)(i.h1,{children:'Introducing the "Bhasha" Series \uD83D\uDE80: Advancements in Indic Language AI Datasets'}),(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{src:"/images/blog_bhasha_wiki/cover.png",alt:"bhasha-wiki on huggingface"})}),(0,s.jsxs)(i.p,{children:['Soket Labs is pleased to announce \uD83E\uDD73 the release of the "Bhasha" series, commencing with two significant datasets: ',(0,s.jsx)(i.a,{href:"https://huggingface.co/datasets/soketlabs/bhasha-wiki",children:'"bhasha-wiki"'})," and ",(0,s.jsx)(i.a,{href:"https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic",children:'"bhasha-wiki-indic"'}),". These datasets are engineered to support the development of AI models that are attuned to the linguistic and cultural nuances of India \uD83E\uDEE1, representing a crucial step forward in the diversification of linguistic resources in computational linguistics. By making these datasets available in an open-source format, we aim to foster a collaborative environment where developers and researchers across India can contribute to and benefit from inclusive and contextually aware AI technologies"]}),(0,s.jsxs)(i.p,{children:["Stay tuned for exciting updates by following us on ",(0,s.jsx)(i.a,{href:"https://www.linkedin.com/company/soketlabs",children:"LinkedIn"})]}),(0,s.jsx)(i.h2,{children:"Bhasha-wiki: A Comprehensive Corpus for Indic Language Research"}),(0,s.jsxs)(i.h3,{children:["Available on Huggingface \uD83E\uDD17: ",(0,s.jsx)(i.a,{href:"https://huggingface.co/datasets/soketlabs/bhasha-wiki",children:"soketlabs/bhasha-wiki"})]}),(0,s.jsx)(i.p,{children:'The "bhasha-wiki" dataset presents a comprehensive corpus consisting of 44.1 million Wikipedia articles translated into six major Indian languages from 6.3 million English articles. This corpus, encompassing over 45.1 billion Indic tokens, serves as a foundational resource for linguistic and AI research, facilitating a wide range of studies into machine translation, natural language processing, and language model training.'}),(0,s.jsx)(i.h3,{children:"Dataset Characteristics:"}),(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Extensive Lexical Volume:"})," The corpus is substantial, with a total size of 117 GiB, containing 44,418,479 rows and over 20 billion words."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Linguistic Diversity:"})," This dataset supports a multilingual framework, including Hindi, Gujarati, Urdu, Tamil, Kannada, Bengali, and English, crucial for cross-linguistic studies."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Translation Methodologies:"})," Utilising IndicTrans2, powered by a significant computational resources (3360 GPU-hours on AWS), each article was translated with high fidelity to the original content. Segmentation and translation were handled sentence-by-sentence, with adaptations made for longer sentences to maintain semantic integrity."]}),"\n"]}),(0,s.jsxs)(i.table,{children:[(0,s.jsx)(i.thead,{children:(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.th,{}),(0,s.jsx)(i.th,{children:"Sentences"}),(0,s.jsx)(i.th,{children:"Characters"}),(0,s.jsx)(i.th,{children:"Words"}),(0,s.jsx)(i.th,{children:"Tokens"}),(0,s.jsx)(i.th,{children:"Rows"})]})}),(0,s.jsxs)(i.tbody,{children:[(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"english"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"19,009,297,439"}),(0,s.jsx)(i.td,{children:"2,954,105,643"}),(0,s.jsx)(i.td,{children:"5,430,358,976"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"hindi"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"18,622,892,252"}),(0,s.jsx)(i.td,{children:"3,382,736,074"}),(0,s.jsx)(i.td,{children:"6,635,241,630"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"kannada"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"19,679,016,421"}),(0,s.jsx)(i.td,{children:"2,349,908,384"}),(0,s.jsx)(i.td,{children:"6,083,839,825"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"bengali"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"18,741,174,694"}),(0,s.jsx)(i.td,{children:"2,663,832,869"}),(0,s.jsx)(i.td,{children:"8,248,287,687"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"gujarati"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"18,453,210,446"}),(0,s.jsx)(i.td,{children:"2,867,239,209"}),(0,s.jsx)(i.td,{children:"6,032,149,490"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"tamil"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"21,457,803,696"}),(0,s.jsx)(i.td,{children:"2,441,061,609"}),(0,s.jsx)(i.td,{children:"6,777,927,96"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"urdu"}),(0,s.jsx)(i.td,{children:"149,636,946"}),(0,s.jsx)(i.td,{children:"17,921,351,051"}),(0,s.jsx)(i.td,{children:"3,641,717,085"}),(0,s.jsx)(i.td,{children:"5,966,954,204"}),(0,s.jsx)(i.td,{children:"6,345,497"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"-"}),(0,s.jsx)(i.td,{children:"-----------"}),(0,s.jsx)(i.td,{children:"------------"}),(0,s.jsx)(i.td,{children:"-------"}),(0,s.jsx)(i.td,{children:"--------"}),(0,s.jsx)(i.td,{children:"------"})]}),(0,s.jsxs)(i.tr,{children:[(0,s.jsx)(i.td,{children:"Total"}),(0,s.jsx)(i.td,{children:"1,04,74,58,622"}),(0,s.jsx)(i.td,{children:"133,884,745,999"}),(0,s.jsx)(i.td,{children:"20,300,600,873"}),(0,s.jsx)(i.td,{children:"45,174,759,774"}),(0,s.jsx)(i.td,{children:"44,418,479"})]})]})]}),(0,s.jsx)(i.p,{children:(0,s.jsx)(i.code,{children:"Note: Tokens are calculated using pragna-1b tokenizer"})}),(0,s.jsx)(i.p,{children:"Characters, words and token distribution for each language is shown in the image."}),(0,s.jsx)(i.p,{children:(0,s.jsx)(i.img,{src:"/images/blog_bhasha_wiki/chars_words_tokens_per_language.png",alt:"bhasha-wiki on huggingface"})}),(0,s.jsx)(i.h2,{children:"Bhasha-wiki-indic: Tailored Dataset for Enhanced Indian Contextual Relevance"}),(0,s.jsxs)(i.h3,{children:["Available on Huggingface: ",(0,s.jsx)(i.a,{href:"https://huggingface.co/datasets/soketlabs/bhasha-wiki-indic",children:"soketlabs/bhasha-wiki-indic"})]}),(0,s.jsx)(i.p,{children:'The "bhasha-wiki-indic" dataset, a refined subset of the "bhasha-wiki", is specifically curated to enrich models with a deeper understanding of the Indian context. This subset was meticulously selected to include content with significant relevance to India, enhancing the potential for developing culturally resonant AI applications.'}),(0,s.jsx)(i.h3,{children:"Methodology:"}),(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Focused Semantic Filtering:"})," Initial filtering employed keyword detection ('india' or 'indian'), refined by a topic classifier, achieving an 84% accuracy in distinguishing relevant content."]}),"\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Content Extraction and Processing:"})," Approximately 208,000 articles were identified as contextually relevant and subsequently extracted for six Indian languages, preparing this dataset as a specialised tool for AI models requiring deep cultural comprehension."]}),"\n"]}),(0,s.jsx)(i.h3,{children:"Dataset Specifications:"}),(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsxs)(i.li,{children:[(0,s.jsx)(i.strong,{children:"Content Volume:"})," The dataset comprises 200,820 rows with nearly 1.54 billion tokens distributed among several languages, providing a rich linguistic base for detailed computational analysis."]}),"\n"]}),(0,s.jsx)(i.h2,{children:"Contributions to the Field and Future Directions"}),(0,s.jsx)(i.p,{children:"These datasets are expected to significantly impact research in computational linguistics and AI by providing high-quality, large-scale resources for training models that require a nuanced understanding of Indian languages and contexts. They also serve as a platform for further scholarly inquiry into algorithmic translations and cultural specificity in AI technologies."}),(0,s.jsx)(i.h2,{children:"Open Access and Collaborative Engagement"}),(0,s.jsx)(i.p,{children:"Released under the CC-by-SA-3.0 licence, these datasets facilitate both academic and commercial use, promoting a wide dissemination and application in diverse settings. We invite the global research community to engage with these resources, further enriching the datasets and exploring new frontiers in AI research."}),(0,s.jsx)(i.p,{children:'As we continue to develop the "Bhasha" series, we remain committed to advancing the state of AI with a focus on ethical considerations and inclusivity in technology.'}),(0,s.jsx)(i.h2,{children:"About Soket Labs:"}),(0,s.jsx)(i.p,{children:"Soket Labs, a visionary AI research firm, is at the forefront of promoting advancements towards ethical Artificial General Intelligence (AGI). Our mission is to foster a form of general intelligence that excels in efficiency and accessibility, thereby democratising cutting-edge technology for diverse applications, including autonomous robots, edge devices, and large clusters."})]})]})}function h(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:i}={...(0,t.a)(),...e.components};return i?(0,s.jsx)(i,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},1528:function(e){e.exports={Blogs:"Blogs_Blogs__7qjHU",sample_table:"Blogs_sample_table__pp3Fe",bench_table:"Blogs_bench_table__rOvgZ"}}}]);